{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyODh27Px7JWIyPWve8XV5mL"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["import nltk\n","nltk.download('punkt')\n","nltk.download('stopwords')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mf0vnoTi6wKB","executionInfo":{"status":"ok","timestamp":1712985979734,"user_tz":-330,"elapsed":777,"user":{"displayName":"Dk","userId":"11449390570484756144"}},"outputId":"b6366cad-a4e9-4676-a167-2a69e975940d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n","[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":5}]},{"cell_type":"code","source":["import re\n","from collections import Counter\n","from nltk.corpus import stopwords\n","from nltk.tokenize import word_tokenize\n","\n","sentences = [\n","    \"The quick brown fox jumps over the lazy dog.\",\n","    \"A quick brown dog outpaces a swift fox.\",\n","    \"The dog and the fox are both brown.\"\n","]\n","\n","sentences_lower = [sentence.lower() for sentence in sentences]\n","\n","def preprocess_text(sentence):\n","    processed_sentence = re.sub(r'[^a-zA-Z\\s]', '', sentence)\n","    tokens = word_tokenize(processed_sentence)\n","    filtered_tokens = [word for word in tokens if word not in stopwords.words('english')]\n","    return filtered_tokens\n","\n","preprocessed_sentences = [preprocess_text(sentence) for sentence in sentences_lower]\n","\n","vocabulary = set()\n","for sentence in preprocessed_sentences:\n","    vocabulary.update(sentence)\n","\n","print(\"Vocabulary:\", vocabulary)\n","\n","bow_vectors = []\n","for sentence in preprocessed_sentences:\n","    bow_vector = Counter(sentence)\n","    bow_vectors.append(bow_vector)\n","\n","for i, bow_vector in enumerate(bow_vectors):\n","    print(\"BoW Vector for Sentence\", i+1, \":\", bow_vector)\n"],"metadata":{"id":"XTtwj1b6Ig2T","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1712985981744,"user_tz":-330,"elapsed":2,"user":{"displayName":"Dk","userId":"11449390570484756144"}},"outputId":"d4dfd176-f8f2-4247-ce3e-d76c3e2f07fa"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Vocabulary: {'swift', 'outpaces', 'lazy', 'jumps', 'quick', 'brown', 'dog', 'fox'}\n","BoW Vector for Sentence 1 : Counter({'quick': 1, 'brown': 1, 'fox': 1, 'jumps': 1, 'lazy': 1, 'dog': 1})\n","BoW Vector for Sentence 2 : Counter({'quick': 1, 'brown': 1, 'dog': 1, 'outpaces': 1, 'swift': 1, 'fox': 1})\n","BoW Vector for Sentence 3 : Counter({'dog': 1, 'fox': 1, 'brown': 1})\n"]}]},{"cell_type":"code","source":[" nltk.download('shakespeare')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"x8BUWkHV7c16","executionInfo":{"status":"ok","timestamp":1712986118200,"user_tz":-330,"elapsed":516,"user":{"displayName":"Dk","userId":"11449390570484756144"}},"outputId":"14f997c9-c797-415b-c660-322691ffd20c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package shakespeare to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/shakespeare.zip.\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":8}]},{"cell_type":"code","source":["from nltk.corpus import shakespeare\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","\n","\n","corpus = [shakespeare.raw(file_id) for file_id in shakespeare.fileids()]\n","\n","tfidf_vectorizer = TfidfVectorizer(stop_words='english')\n","tfidf_matrix = tfidf_vectorizer.fit_transform(corpus)\n","\n","print(\"TF-IDF Matrix:\")\n","print(tfidf_matrix.toarray())\n","\n","# Displaying Vocabulary\n","print(\"Vocabulary:\")\n","print(tfidf_vectorizer.get_feature_names_out())\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ok1gxC9j6qmM","executionInfo":{"status":"ok","timestamp":1712986122088,"user_tz":-330,"elapsed":644,"user":{"displayName":"Dk","userId":"11449390570484756144"}},"outputId":"4c9b5604-fe0f-48ef-a85a-f080d0485c5f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["TF-IDF Matrix:\n","[[0.00012503 0.00012503 0.00012503 ... 0.         0.         0.        ]\n"," [0.00021722 0.00021722 0.00021722 ... 0.         0.         0.        ]\n"," [0.00011343 0.00011343 0.00011343 ... 0.         0.00028404 0.        ]\n"," ...\n"," [0.00017566 0.00017566 0.00017566 ... 0.00043987 0.         0.        ]\n"," [0.00012426 0.00012426 0.00012426 ... 0.         0.         0.00078231]\n"," [0.0001477  0.0001477  0.0001477  ... 0.         0.         0.00061994]]\n","Vocabulary:\n","['1992' '1996' '1998' ... 'zeal' 'zone' 'zounds']\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fD1BBqgqC1p1","executionInfo":{"status":"ok","timestamp":1712384711348,"user_tz":-330,"elapsed":4157,"user":{"displayName":"Dk","userId":"11449390570484756144"}},"outputId":"7cf96a0a-5513-451d-9261-81330c50bdd3"},"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n","[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n","[nltk_data] Downloading package wordnet to /root/nltk_data...\n"]},{"output_type":"stream","name":"stdout","text":["Vocabulary: ['text', 'data', 'yet', 'another', 'sample', 'example', 'sentence']\n","\n","TF-IDF Scores:\n","Document 1 : {'sample': 0.5493061443340549, 'sentence': 0.2027325540540822}\n","Document 2 : {'another': 0.13515503603605478, 'example': 0.13515503603605478, 'sentence': 0.13515503603605478}\n","Document 3 : {'yet': 0.21972245773362198, 'another': 0.08109302162163289, 'example': 0.08109302162163289, 'text': 0.21972245773362198, 'data': 0.21972245773362198}\n"]}],"source":["from nltk.corpus import stopwords\n","from nltk.tokenize import word_tokenize\n","from nltk.stem import WordNetLemmatizer\n","from collections import Counter\n","import string\n","import math\n","\n","def preprocess_text(text):\n","    text = text.lower()\n","    text = text.translate(str.maketrans('', '', string.punctuation))\n","    tokens = word_tokenize(text)\n","    stop_words = set(stopwords.words('english'))\n","    filtered_tokens = [word for word in tokens if word not in stop_words]\n","    lemmatizer = WordNetLemmatizer()\n","    lemmatized_tokens = [lemmatizer.lemmatize(word) for word in filtered_tokens]\n","    return lemmatized_tokens\n","\n","def bag_of_words(texts):\n","    vocabulary = set()\n","    for text in texts:\n","        vocabulary.update(text)\n","    return list(vocabulary)\n","\n","def tf_idf(corpus):\n","    tf_corpus = []\n","    for document in corpus:\n","        tf_document = {}\n","        word_counts = Counter(document)\n","        total_words = len(document)\n","        for word, count in word_counts.items():\n","            tf_document[word] = count / total_words\n","        tf_corpus.append(tf_document)\n","\n","    idf = {}\n","    num_documents = len(corpus)\n","    for document in corpus:\n","        for word in set(document):\n","            idf[word] = idf.get(word, 0) + 1\n","\n","    for word, freq in idf.items():\n","        idf[word] = math.log(num_documents / freq)\n","\n","    tf_idf_corpus = []\n","    for tf_document in tf_corpus:\n","        tf_idf_document = {}\n","        for word, tf in tf_document.items():\n","            tf_idf_document[word] = tf * idf[word]\n","        tf_idf_corpus.append(tf_idf_document)\n","\n","    return tf_idf_corpus\n","\n","texts = [\n","    \"This is a sample sentence.\",\n","    \"Another example sentence.\",\n","    \"Yet another example of text data.\"\n","]\n","\n","preprocessed_texts = [preprocess_text(text) for text in texts]\n","\n","# Bag of Words model\n","vocabulary = bag_of_words(preprocessed_texts)\n","print(\"Vocabulary:\", vocabulary)\n","\n","# TF-IDF model\n","tf_idf_scores = tf_idf(preprocessed_texts)\n","print(\"\\nTF-IDF Scores:\")\n","for i, document in enumerate(tf_idf_scores):\n","    print(\"Document\", i+1, \":\", document)\n"]},{"cell_type":"code","source":["from sklearn.feature_extraction.text import TfidfVectorizer\n","\n","sentences = [\n","    \"The quick brown fox jumps over the lazy dog.\",\n","    \"A quick brown dog outpaces a swift fox.\",\n","    \"The dog and the fox are both brown.\"\n","]\n","\n","sentences_lower = [sentence.lower() for sentence in sentences]\n","\n","tfidf_vectorizer = TfidfVectorizer()\n","\n","tfidf_matrix = tfidf_vectorizer.fit_transform(sentences_lower)\n","\n","print(\"TF-IDF Matrix:\")\n","print(tfidf_matrix.toarray())\n","\n","print(\"Vocabulary:\")\n","print(tfidf_vectorizer.get_feature_names_out())\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jdr6qQ1o7aLK","executionInfo":{"status":"ok","timestamp":1712986167637,"user_tz":-330,"elapsed":540,"user":{"displayName":"Dk","userId":"11449390570484756144"}},"outputId":"4bba86d9-567b-4ddb-8940-549a7ef70569"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["TF-IDF Matrix:\n","[[0.         0.         0.         0.22421937 0.22421937 0.22421937\n","  0.3796364  0.3796364  0.         0.3796364  0.28872327 0.\n","  0.57744654]\n"," [0.         0.         0.         0.31021184 0.31021184 0.31021184\n","  0.         0.         0.52523431 0.         0.39945423 0.52523431\n","  0.        ]\n"," [0.3965233  0.3965233  0.3965233  0.23419305 0.23419305 0.23419305\n","  0.         0.         0.         0.         0.         0.\n","  0.60313238]]\n","Vocabulary:\n","['and' 'are' 'both' 'brown' 'dog' 'fox' 'jumps' 'lazy' 'outpaces' 'over'\n"," 'quick' 'swift' 'the']\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"Rx4dZRn17pJC"},"execution_count":null,"outputs":[]}]}